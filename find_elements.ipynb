{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Test Likelihood Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skyfield.data import mpc\n",
    "from skyfield.api import load, N, W, wgs84\n",
    "from misc import epoch2jd, chi2fun, ln_like\n",
    "\n",
    "# Load Sun Earth ephemeris\n",
    "eph = load('MPC/de421.bsp')\n",
    "sun, earth = eph['sun'], eph['earth']\n",
    "# Site\n",
    "obs_site = earth + wgs84.latlon(35.904613 * N, 79.046761 * W)\n",
    "# Asteroid\n",
    "target = '2012FN62'\n",
    "# Load orbital elements\n",
    "with load.open(f'MPC/MPCORB.{target}.DAT') as f:\n",
    "    minor_planets = mpc.load_mpcorb_dataframe(f)\n",
    "row = minor_planets.loc[0].copy() # Create an explicit copy\n",
    "\n",
    "# template orbital elements (Panda Series)\n",
    "elms = row.copy()\n",
    "\n",
    "# array of truth element\n",
    "truths = np.array([row.semimajor_axis_au,\n",
    "                   row.eccentricity,\n",
    "                   row.inclination_degrees,\n",
    "                   row.longitude_of_ascending_node_degrees,\n",
    "                   row.argument_of_perihelion_degrees,\n",
    "                   row.mean_anomaly_degrees])\n",
    "# MPC epoch_packed to JD\n",
    "truths_T = epoch2jd(row.epoch_packed)\n",
    "\n",
    "# load csv file\n",
    "datafile = '2012FN62_s150_n3'\n",
    "cat = pd.read_csv(f'sim_data/{datafile}.csv')\n",
    "jds = np.array(cat.JD)\n",
    "ras = np.array(cat.RA_obs)\n",
    "decs = np.array(cat.Dec_obs)\n",
    "perr = np.array(cat.perr)\n",
    "\n",
    "# parameter names and boundaries\n",
    "params = ['$a$','$e$','$i$','$\\Omega$', '$\\omega$', '$MA$']\n",
    "bounds = np.array([[2.0,   0,  0,   0,  0,    0],\n",
    "                   [3.5, 0.9, 30, 360, 360, 360]])\n",
    "\n",
    "# test Likelihood and Chi^2 functions\n",
    "# Set print options to display 2 decimal places\n",
    "np.set_printoptions(formatter={'float': '{:.2f}'.format})\n",
    "print(f\"(a,e,i,Omega,omega,MA) @ Epoch: {truths} @ {truths_T}\")\n",
    "print(ln_like(truths,bounds,elms,jds,ras,decs,perr))\n",
    "print(chi2fun(truths,elms,jds,ras,decs,perr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMOEBA\n",
    "\n",
    "Use a downhill simplex method with simulated annealing (`amoeba_sa`) \n",
    "to search for the best-fit orbital elements in the large 6-dimensional \n",
    "parameter space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Computing Time on M2 Macbook Air: \n",
    "    2m for 10 iterations of nmax = 1000 steps\n",
    "\"\"\"\n",
    "from amoeba import amoeba_sa\n",
    "\n",
    "def func(p): return chi2fun(p,elms,jds,ras,decs,perr)\n",
    "\n",
    "# Parameters for simulated annealing\n",
    "niter = 10\n",
    "cooling = 1.0 / niter\n",
    "temp0 = len(jds)\n",
    "scl0 = (bounds[1,:]-bounds[0,:])/3\n",
    "p0 = (bounds[1,:]+bounds[0,:])/2\n",
    "\n",
    "# Set print options to display 2 decimal places\n",
    "np.set_printoptions(formatter={'float': '{:.2f}'.format})\n",
    "\n",
    "# truth chisq and initial guess chisq\n",
    "print(f\"(a,e,i,Omega,omega,MA): {truths}\")\n",
    "print(f\"Truth chi-squared: {func(truths)}\")\n",
    "print(f\"(a,e,i,Omega,omega,MA): {p0}\")\n",
    "print(f\"Initial chi-squared: {func(p0)}\")\n",
    "\n",
    "# Run simulated annealing\n",
    "for i in range(niter):\n",
    "    temp = temp0 * (1.0 - cooling * i)\n",
    "    scl = scl0 * (1.0 - cooling * i / 2.0)\n",
    "    best_params, result = amoeba_sa(1e-5, function_name=func, \n",
    "                                    p0=p0, scale=scl, \n",
    "                                    upper=bounds[1,:], lower=bounds[0,:],\n",
    "                                    temperature=temp, nmax=1000)\n",
    "    p0 = best_params.copy()  # Use the best parameters as the starting point for the next iteration\n",
    "    # show progress\n",
    "    print(f\"(a,e,i,Omega,omega,MA): {best_params}\")\n",
    "    print(f\"Minimum chi-squared: {np.min(result['chi2'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Predicted Positions with True Positions on a Longer Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from misc import predict_pos\n",
    "\n",
    "# extend the JD range by 600 days\n",
    "jdextra = np.linspace(np.min(jds),np.min(jds)+600)\n",
    "# predict positions based on true elements\n",
    "theta = truths.copy()\n",
    "ra_true, dec_true, _ = predict_pos(theta, elms, jdextra)\n",
    "# predict positions based on best-fit elements\n",
    "theta = best_params.copy()\n",
    "ra_pred, dec_pred, _ = predict_pos(theta, elms, jdextra)\n",
    "# plot the RA and Dec residuals\n",
    "plt.plot(jdextra-np.min(jds),ra_true._degrees-ra_pred._degrees,'-',\n",
    "         jdextra-np.min(jds),dec_true._degrees-dec_pred._degrees,'--')\n",
    "# show observed dates\n",
    "plt.plot(jds-np.min(jds),[0,0,0],'bo')\n",
    "plt.axhline(0,linestyle=':');\n",
    "\n",
    "# print predicted postions at the observing times\n",
    "print(jds,ras, decs)\n",
    "theta = best_params.copy()\n",
    "ra_pred, dec_pred, _ = predict_pos(theta, elms, jds)\n",
    "print(ra_pred._degrees,dec_pred._degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MCMC-sampling with multiprocessing \"\"\"\n",
    "\"\"\" 100%|██████████| 1000/1000 [00:52<00:00, 19.06it/s] \"\"\"\n",
    "\"\"\" MCMC-sampling with single processing \"\"\"\n",
    "\"\"\" 100%|██████████| 1000/1000 [04:09<00:00,  4.01it/s] \"\"\"\n",
    "\n",
    "import multiprocessing, emcee, os\n",
    "import numpy as np\n",
    "\n",
    "# prep for multithreading\n",
    "multiprocessing.set_start_method(\"fork\")   # fork: copy a Python process from an existing process.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"        # disable automatic parallelization in NumPy\n",
    "\n",
    "# need 8500 steps for chains to converge: nsteps/max(tau) > 50\n",
    "nsteps = 10000 \n",
    "nrepeat = 1\n",
    "converge_check = True\n",
    "\n",
    "emcfile = f'results/{datafile}.h5'\n",
    "if os.path.exists(emcfile): os.remove(emcfile)\n",
    "\n",
    "\"\"\" initial starting positions of the walkers \"\"\"\n",
    "cnter = best_params\n",
    "print(cnter)\n",
    "ncpu = 8\n",
    "ndim = len(bounds[0,:])\n",
    "nwalkers = ncpu*int(np.ceil(2.5*ndim/ncpu)) \n",
    "scale = (bounds[1,:]-bounds[0,:])/50\n",
    "pos = cnter + scale*(np.random.normal(size=(nwalkers, ndim)))\n",
    "# clip initial positions outside of bounds\n",
    "for i in range(ndim):\n",
    "    pos[:,i] = np.clip(pos[:,i], bounds[0,i], bounds[1,i]) \n",
    "\n",
    "for irepeat in range(1,nrepeat+1):\n",
    "    print(f'\\nThis is {irepeat=} out of {nrepeat=}')\n",
    "    # set up backend to save MCMC samples\n",
    "    backend = emcee.backends.HDFBackend(emcfile)\n",
    "    if not os.path.exists(emcfile): \n",
    "        print(f'Reset backend because {emcfile} not present')\n",
    "        backend.reset(nwalkers, ndim)\n",
    "        print(f'Start MCMC from initial random positions')\n",
    "        instate = pos\n",
    "        chainexist = False\n",
    "    else: \n",
    "        print(f'Start MCMC from where left off the last time in {emcfile}')\n",
    "        instate = None\n",
    "        chainexist = True\n",
    "\n",
    "    # set up sampler \n",
    "    with multiprocessing.Pool() as pool:\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, \n",
    "                ln_like, args=(bounds,elms,jds,ras,decs,perr), \n",
    "                pool=pool, backend=backend)\n",
    "        # check if chain is already long enough\n",
    "        if chainexist and converge_check:\n",
    "            chainshape = sampler.get_chain().shape\n",
    "            tau = sampler.get_autocorr_time(quiet=True)\n",
    "            flat_samples = sampler.get_chain(flat=True) \n",
    "            log_probs = sampler.get_log_prob(flat=True)\n",
    "            map_idx = np.argmax(log_probs)  # Index of the MAP sample\n",
    "            map_params = flat_samples[map_idx]   # Parameters at MAP\n",
    "            print(f\"MAP: {log_probs[map_idx]}, parameters: {map_params}\")\n",
    "            if chainshape[0] > 50*np.max(tau): \n",
    "                print(\"[Break]: Chain length already exceeds 50x Auto-correlation Time\")\n",
    "                break \n",
    "        # start walking\n",
    "        sampler.run_mcmc(instate, nsteps, progress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Plots to Show Covariances amongst Orbital Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" make a corner plot over full bounded range \"\"\"\n",
    "import emcee, corner\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sampler = emcee.backends.HDFBackend(emcfile)\n",
    "nstep, nwalker, ndim = sampler.get_chain().shape\n",
    "# use trimmed, thinned, flattened sample for corner plots\n",
    "tau = sampler.get_autocorr_time(quiet=True)\n",
    "burnin = int(2 * np.max(tau))\n",
    "thin = int(0.5 * np.min(tau))\n",
    "flat_samples = sampler.get_chain(discard=burnin, flat=True, thin=thin)\n",
    "mids = np.array([np.percentile(flat_samples[:,i],50) for i in range(ndim)])\n",
    "_ = corner.corner(flat_samples, labels=params, truths=truths,\n",
    "        title_quantiles=[0.16,0.50,0.84], quantiles=[0.50],\n",
    "        show_titles=True, plot_contours=False, plot_density=False, bins=50,\n",
    "        range=list(zip(bounds[0],bounds[1])))\n",
    "plt.savefig(f'{emcfile.replace(\".h5\",\"\")}_{nstep}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = corner.corner(flat_samples, labels=params, truths=truths,\n",
    "        title_quantiles=[0.16,0.50,0.84], quantiles=[0.50],\n",
    "        show_titles=True, plot_contours=False, plot_density=False, bins=50)\n",
    "plt.savefig(f'{emcfile.replace(\".h5\",\"\")}_{nstep}_zoom.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
